{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac1c336",
   "metadata": {},
   "source": [
    "# PKS Vorverarbeitung\n",
    "Dieses Notebook verarbeitet die Polizeiliche Kriminalstatistik (PKS).\n",
    "\n",
    "Ablauf:\n",
    "1. Excel-Rohdaten in CSV umwandeln (Header-Bereinigung)\n",
    "2. CSVs mit Spark laden und Spalten bereinigen\n",
    "3. Deutsche + Nichtdeutsche joinen\n",
    "4. Als `pks_complete.parquet` speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.config_local import get_spark_session\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = get_spark_session(\"PKS_Vorverarbeitung\")\n",
    "\n",
    "RAW_DIR = \"../data/raw/\"\n",
    "PROC_DIR = \"../data/processed/\"\n",
    "os.makedirs(PROC_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2685502",
   "metadata": {},
   "source": [
    "Excel -> CSV\n",
    "\n",
    "Die PKS-Rohdaten liegen als `.xlsx` vor. Die ersten Zeilen enthalten Metadaten, der eigentliche Header beginnt bei der Zeile mit \"Schlüssel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ad6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PKS_FILES = [\n",
    "    \"ZR-TV-04-T40-TV-insg-deutsch_xls.xlsx\", \n",
    "    \"ZR-TV-07-T50-TV-insg-nichtdeutsch_xls.xlsx\"\n",
    "]\n",
    "\n",
    "for file in PKS_FILES:\n",
    "    input_path = os.path.join(RAW_DIR, file)\n",
    "    output_path = os.path.join(RAW_DIR, file.replace(\".xlsx\", \".csv\"))\n",
    "    \n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Datei nicht gefunden: {input_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Konvertiere {file} ...\")\n",
    "    \n",
    "    # Alles als String lesen, Formatierungsfehler vermeiden\n",
    "    df = pd.read_excel(input_path, header=None, dtype=str)\n",
    "    \n",
    "    # Header beginnt immer bei \"Schlüssel\" (PKS-Standard)\n",
    "    start_row = df[df[0] == \"Schlüssel\"].index[0]\n",
    "    df_clean = pd.read_excel(input_path, header=start_row)\n",
    "    \n",
    "    df_clean.to_csv(output_path, index=False, sep=\";\", encoding=\"utf-8\")\n",
    "    print(f\" -> {output_path}\")\n",
    "\n",
    "print(\"CSV-Konvertierung abgeschlossen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e4d85",
   "metadata": {},
   "source": [
    "CSVs laden und bereinigen\n",
    "\n",
    "Die Spalte `Tatver-dächtige  insgesamt` wird zu `anzahl` umbenannt. Jahr und Anzahl werden über Double nach Int gecastet, weil Excel-Export teilweise Werte wie `\"1987.0\"` erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5405d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_pks(filename):\n",
    "    \"\"\"Lädt eine PKS-CSV und gibt ein bereinigtes DataFrame zurück.\"\"\"\n",
    "    df = spark.read.option(\"header\", \"true\") \\\n",
    "                   .option(\"delimiter\", \";\") \\\n",
    "                   .csv(f\"{RAW_DIR}{filename}\")\n",
    "    \n",
    "    # Spaltenname variiert je nach Excel-Export\n",
    "    if \"Tatver-dächtige  insgesamt\" in df.columns:\n",
    "        df = df.withColumnRenamed(\"Tatver-dächtige  insgesamt\", \"anzahl\")\n",
    "    \n",
    "    # Double -> Int Cast, weil Excel \"1987.0\" statt \"1987\" exportiert\n",
    "    df_clean = df.select(\n",
    "        col(\"Schlüssel\").alias(\"schluessel\"),\n",
    "        col(\"Straftat\").alias(\"straftat\"),\n",
    "        col(\"Jahr\").cast(\"double\").cast(\"int\").alias(\"jahr\"),\n",
    "        col(\"anzahl\").cast(\"double\").cast(\"int\").alias(\"anzahl\")\n",
    "    )\n",
    "    \n",
    "    # Footer-Zeilen und ungültige Jahre rausfiltern\n",
    "    df_clean = df_clean.filter((col(\"jahr\").isNotNull()) & (col(\"jahr\") > 1900))\n",
    "    return df_clean\n",
    "\n",
    "# Beide Dateien laden\n",
    "df_de = load_and_clean_pks(\"ZR-TV-04-T40-TV-insg-deutsch_xls.csv\")\n",
    "df_nd = load_and_clean_pks(\"ZR-TV-07-T50-TV-insg-nichtdeutsch_xls.csv\")\n",
    "\n",
    "print(f\"Deutsche:       {df_de.count()} Zeilen\")\n",
    "print(f\"Nichtdeutsche:  {df_nd.count()} Zeilen\")\n",
    "df_de.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ce423",
   "metadata": {},
   "source": [
    "Join und Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl-Spalten umbenennen für den Join\n",
    "df_de = df_de.withColumnRenamed(\"anzahl\", \"anzahl_deutsch\")\n",
    "df_nd = df_nd.withColumnRenamed(\"anzahl\", \"anzahl_nichtdeutsch\")\n",
    "\n",
    "# Inner Join über die gemeinsamen Schlüssel\n",
    "df_pks = df_de.join(df_nd, on=[\"jahr\", \"schluessel\", \"straftat\"], how=\"inner\")\n",
    "\n",
    "# Gesamtanzahl berechnen\n",
    "df_pks = df_pks.withColumn(\"anzahl_gesamt\", col(\"anzahl_deutsch\") + col(\"anzahl_nichtdeutsch\"))\n",
    "\n",
    "# Einzelne Teildaten + kombiniertes Ergebnis speichern\n",
    "df_de.write.mode(\"overwrite\").parquet(f\"{PROC_DIR}pks_deutsche_clean.parquet\")\n",
    "df_nd.write.mode(\"overwrite\").parquet(f\"{PROC_DIR}pks_nichtdeutsche_clean.parquet\")\n",
    "df_pks.write.mode(\"overwrite\").parquet(f\"{PROC_DIR}pks_complete.parquet\")\n",
    "\n",
    "print(f\"pks_complete: {df_pks.count()} Zeilen\")\n",
    "df_pks.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
